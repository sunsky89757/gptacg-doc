# 提示词工程

>本指南分享了在大型语言模型中获取更好结果的策略和战术。这里描述的方法有时可以结合使用以取得更好的效果。我们鼓励大家进行实验，找出最适合自己的方法。

## 六种获得更好结果的策略

### 1. 写清晰的指令

这些模型无法读懂你的想法。如果输出内容太长，请要求简洁的回复。如果输出内容过于简单，请要求专家级的写作。如果是你不喜欢格式，演示一下你希望看到的格式。模型猜测的内容越少，你就越有可能得到你想要的东西。

策略:

- 在提问中包含详细信息，以获得更相关的答案
- 要求模型扮演某个角色
- 使用分隔符清晰的区分输入的指定部分
- 指定完成任务所需的步骤
- 提供示例
- 指定输出的期望长度

### 2. 提供参考文本

语言模型可以自信地编造虚假答案，尤其是在被问及深奥话题或要求提供出处时。就像一本笔记可以帮助学生在考试中取得更好成绩一样，向这些模型提供参考文本可以帮助它们减少编造答案。

策略：

- 指示模型使用参考文本进行回答
- 指示模型在回答时引用参考文本

### 3. 将复杂的任务分解为更简单的子任务

正如在软件工程中将一个复杂系统分解为一组模块化组件是一个很好的实践方法，对于提交给语言模型的任务也是如此。复杂的任务往往比简单的任务有更高的错误率。此外，复杂的任务通常可以重新定义为更简单任务的工作流，其中早期任务的输出用于构建后续任务的输入。

策略:

- 使用意图分类来识别与用户查询最相关的指令
- 对于需要非常长对话的对话应用程序,总结或过滤先前的对话
- 分段总结长文档,并递归地构建完整摘要

### 4. 给模型时间"思考"

如果有人让你算一下17x28等于多少，你可能不能马上得出答案，但如果给你时间，你仍然可以算出来。类似地，与花时间推理出答案相比，模型在试图立即回答时更容易出现推理错误。在给出答案之前，要求提供"解题思路"可以帮助模型更可靠地推理出正确答案。

策略:

- 指示模型在匆忙得出结论之前,自己先推导出解题思路
- 使用内心独白或一系列问题来隐藏模型的推理过程
- 询问模型在之前的尝试中是否遗漏了什么

### 5. 结合外部工具

通过将其他工具的输出输入模型，以弥补模型的缺陷。例如，文本检索系统（有时称为RAG或检索增强生成）可以告诉模型相关文档。像OpenAI的代码解释器这样的代码执行引擎可以帮助模型进行数学运算和运行代码。如果一项任务可以通过工具更可靠或更高效地完成，而不是通过语言模型完成，那么将其分配给工具，以结合两者的优势。

策略：

- 使用基于嵌入的搜索来实施高效的知识检索
- 使用代码执行来执行更准确的计算或调用外部API
- 给予模型访问特定功能的权限

### 6. 系统性地测试变更

如果能够量化性能，就能更轻松地改进性能。有时，对提示的修改可能在少数个别例子中表现更好，但在更广泛的例子集中却会整体表现变差。所以，为了确保变更能整体提升性能，可能需要定义一个全面的测试套件（即“评估”）。

策略：

- 通过对比参考标准答案来评估模型输出

?>每个以上列出的策略都可以通过具体的战术来实现。这些战术旨在提供一些尝试的想法。它们绝不全面详尽，您可以自由尝试这里未提及的创意。

## 六种策略的具体示范

### 1. 写清晰的指令

**在提问中包含详细信息，以获得更相关的答案**

为了确保得到精准的回复，请提供所有重要的细节或上下文信息。否则，模型可能会误解您的意思。

| 不推荐                   | 推荐                                                                                                                   |
| ------------------------ | ---------------------------------------------------------------------------------------------------------------------- |
| 如何在 Excel 中添加数字  | 如何在 Excel 中汇总一行美元金额？我想自动对整张工作表中的所有行进行汇总，并将所有总数放在名为“Total”的列的右侧。       |
| 总统是谁                 | 2021年墨西哥总统是谁，选举多久举行一次？                                                                               |
| 编写代码计算斐波那契数列 | 编写一个TypeScript函数高效计算斐波那契数列。详细注释代码，解释每个部分的作用以及为何这样编写。                         |
| 总结会议记录             | 用一个段落总结会议记录。然后写一个包括发言人及其要点的markdown列表。最后，列出发言人建议的下一步或行动项目（如果有）。 |

**要求模型扮演某个角色**

在请求体中，"role": "system" 部分的content可以定义角色信息。如下所示

```python
"messages": [
      {
         "role": "system",
         "content": "You are a helpful assistant.（此处的内容可以修改为自定义角色的描述）"  
      },
      {
         "role": "user",
         "content": "你好（此处为你提问的问题）"
      }
   ]
```

>**system：**<br>当我请你帮忙写东西时，你会回复一份文档，每段至少包含一个笑话或俏皮话。<br>
>**user：**<br>请向我的钢螺栓供应商写一封感谢信，感谢他们在这么短的时间内按时送货。这让我们顺利完成了一个重要订单的交付。

**使用分隔符清晰的区分输入的指定部分**

分隔符如三重引号、XML标签、章节标题等可以帮助划分需要区别对待的文本部分。

>**user：**<br>请将三引号中的文本总结为一首俳句。<br>"""文本在此处插入"""

>```
>system：
>你将得到一对关于同一话题的文章（用XML标签分隔）。首先总结每篇文章的论点。然后指出哪篇文章的论点更好，并解释原因。
>user：
><article>在此处插入第一篇文章</article>
><article>在此处插入第二篇文章</article>
>```

>**system：**<br>你将收到一份论文摘要和一个建议的标题。论文标题应该清晰地反映论文主题，并且具有吸引力。如果标题不符合这些标准，请提供5个备用标题。<br>
>**user：**<br>摘要：xxx<br>标题：xxx

对于这种简单的任务，使用分隔符可能并不会影响输出质量。然而，任务越复杂，区分任务细节就越重要。请明确表达你的要求，不要让模型费力去猜测你的意图。

**指定完成任务所需的步骤**

某些任务最好分解为一系列步骤。明确列出这些步骤可以让模型更容易遵循。

>**system：**<br>请按照以下步骤处理用户输入。<br>步骤1 - 用户会在三引号中提供文字。将这段文字总结成一句话，前缀为“Summary: ”。<br>步骤2 - 将步骤1中的总结翻译成西班牙语，前缀为“Translation: ”<br>
>**user：**<br>"""插入的文本"""

**提供示例**

提供适用于所有情况的一般指示通常比通过示例演示任务的各种形式更有效，但在某些情况下，提供示例可能会更容易。例如，如果您希望模型模仿某种特定的回应用户查询的风格，而这种风格难以清晰描述。这种方法被称为“少样本”提示。

>**system：**<br>以举例中一致的风格作答。例如：教我关于耐心的知识。你的回答：耐心是磨盘，越久越香。<br>
>**user：**<br>教我关于耐心的知识。<br>

**指定输出的期望长度**

可以要求模型生成具有特定长度的输出。这种长度可以用单词、句子、段落或要点的数量来表示。不过，请注意，让模型生成特定数量的单词时，精确度可能不高。相对而言，模型在生成特定数量的段落或要点时会更加准确。

>**user：**<br>总结由三引号分隔的文本，字数约为50字。<br>"""插入的文本"""

>**user：**<br>用两段话总结由三引号分隔的文本。<br>"""插入的文本"""

>**user：**<br>用三点总结以下用三引号括起来的文本。<br>"""插入的文本"""

### 2. 提供参考文本

**指示模型使用参考文本进行回答**

如果我们能为模型提供与当前查询相关的可信信息，那么我们可以指导模型利用这些信息来生成答案。